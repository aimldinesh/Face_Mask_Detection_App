{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face_Mask_Detection_App.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_9sasIMgxHb"
      },
      "source": [
        "## **Face_Mask_Detection_App_Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHqbLE_khDQ-"
      },
      "source": [
        "pip install tensorflow==2.1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LImVpsUhIdh"
      },
      "source": [
        "pip install keras==2.3.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjOJDFndhMM_"
      },
      "source": [
        "#Training Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_K7sy2UhjyE"
      },
      "source": [
        "# Import Labraries\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H77_qFxuidjW"
      },
      "source": [
        "# Import Visualization Libraries\n",
        "import matplotlib.pyplot as plt "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkxGQsSEi0B5"
      },
      "source": [
        "# Import tensorflow\n",
        "import tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgAbWO0fjB9w"
      },
      "source": [
        "print(tensorflow.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iprAELAGjKZk"
      },
      "source": [
        "print(keras.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RG042A8ojO8r"
      },
      "source": [
        "# path train  and Validation data\n",
        "train_data_path = \"/content/drive/My Drive/Colab Notebooks/Face_Mask_Detection_App/dataset/train\"\n",
        "Validation_data_path = \"/content/drive/My Drive/Colab Notebooks/Face_Mask_Detection_App/dataset/valid\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdFih0iHj9_T"
      },
      "source": [
        "# show augmented images function\n",
        "def plotImages(images_arr):\n",
        "    fig, axes = plt.subplots(1, 5, figsize=(20, 20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip(images_arr, axes):\n",
        "        ax.imshow(img)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKyD1Rk_l32l"
      },
      "source": [
        "# augmentation configuration we will use for training\n",
        "# It generate more images using below parameters\n",
        "training_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                      rotation_range=40,\n",
        "                                      width_shift_range=0.2,\n",
        "                                      height_shift_range=0.2,\n",
        "                                      shear_range=0.2,\n",
        "                                      zoom_range=0.2,\n",
        "                                      horizontal_flip=True,\n",
        "                                      fill_mode='nearest')\n",
        "\n",
        "# this is a geneartor that will read pictures found in at train_data_path,\n",
        "# and indefinitely generate batches of augmented image data\n",
        "training_data = training_datagen.flow_from_directory(train_data_path, target_size=(200,200),\n",
        "                                                     batch_size = 128,\n",
        "                                                     class_mode = 'binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "794IQVn8pTES"
      },
      "source": [
        "training_data.class_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prQnFowVtmV6"
      },
      "source": [
        "# augmentation configuration we will use for validation --> only rescaling\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# this is a geneartor that will read pictures found in at validation_data_path,\n",
        "# and indefinitely generate batches of augmented image data\n",
        "validation_data = validation_datagen.flow_from_directory(Validation_data_path,\n",
        "                                  target_size=(200,200),\n",
        "                                  batch_size=128,\n",
        "                                  class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJRgeKRYu7be"
      },
      "source": [
        "# Show Augmented Images\n",
        "images = [training_data[0][0][0] for i in range(5)]\n",
        "plotImages(images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuefmDcxxHPD"
      },
      "source": [
        "# Save best Model using Vall accuracy\n",
        "save_model_path = '/content/drive/My Drive/Colab Notebooks/Face_Mask_Detection_App/model/model.h5'\n",
        "checkpoint = ModelCheckpoint(save_model_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Yn7dPEp3jVn"
      },
      "source": [
        "## **Building CNN Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9mEfZng30Vk"
      },
      "source": [
        "cnn_model = keras.models.Sequential([\n",
        "                                      keras.layers.Conv2D(filters=32, kernel_size=5, input_shape=[200, 200, 3]),\n",
        "                                      keras.layers.MaxPooling2D(pool_size=(4,4)),\n",
        "                                      keras.layers.Conv2D(filters=64, kernel_size=4),\n",
        "                                      keras.layers.MaxPooling2D(pool_size=(3,3)),\n",
        "                                      keras.layers.Conv2D(filters=128, kernel_size=3),\n",
        "                                      keras.layers.MaxPooling2D(pool_size=(2,2)),                                    \n",
        "                                      keras.layers.Conv2D(filters=256, kernel_size=2),\n",
        "                                      keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
        "                                      keras.layers.Dropout(0.5),\n",
        "                                      keras.layers.Flatten(), # neural network building\n",
        "                                      keras.layers.Dense(units=128, activation='relu'), # input layer\n",
        "                                      keras.layers.Dropout(0.1),\n",
        "                                      keras.layers.Dense(units=256, activation= 'relu'),\n",
        "                                      keras.layers.Dropout(0.25),\n",
        "                                      keras.layers.Dense(units=2, activation='softmax') # output layer\n",
        "\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdTRF3a57CYQ"
      },
      "source": [
        "## **Compile CNN Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLch8ah97WCG"
      },
      "source": [
        "#cnn_model.compile(optimizer = Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "cnn_model.compile(optimizer= Adam(lr = 0.001), loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdCxlW988mxu"
      },
      "source": [
        "## **Train CNN Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZAfweuH8s38"
      },
      "source": [
        "history = cnn_model.fit(training_data, epochs=50, verbose=1, validation_data=validation_data, callbacks=callbacks_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiKQW5_TrgjQ"
      },
      "source": [
        "## **Plots Loss & Accuracy** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGBJdlsdr4Qf"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# plot loss\n",
        "plt.plot(cnn_model.history.history['loss'], label='train_loss')\n",
        "plt.plot(cnn_model.history.history['val_loss'], label='val_loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('Loss_Val')\n",
        " \n",
        "# plot accuracy\n",
        "plt.plot(cnn_model.history.history['accuracy'], label='train_acc')\n",
        "plt.plot(cnn_model.history.history['val_accuracy'], label='val_acc')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.savefig('Accuracy_Val')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omflr245uZEu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}